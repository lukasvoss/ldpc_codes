{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full parameter search for new LPDC codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "from numpy.linalg import matrix_power as matrix_power\n",
    "from numpy.linalg import matrix_rank as matrix_rank\n",
    "\n",
    "\n",
    "from mip import Model, xsum, minimize, BINARY\n",
    "from bposd.css import css_code\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "from parallel_functions import process_combination\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format=\"%(asctime)s INFO %(message)s\",  # hardcoded INFO level\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_encoding_rate(k, n):\n",
    "    return k / (2*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the minimum Hamming weight of a binary vector x such that\n",
    "# stab @ x = 0 mod 2\n",
    "# logicOp @ x = 1 mod 2\n",
    "# here stab is a binary matrix and logicOp is a binary vector\n",
    "def distance_test(stab,logicOp):\n",
    "  # number of qubits\n",
    "  n = stab.shape[1]\n",
    "  # number of stabilizers\n",
    "  m = stab.shape[0]\n",
    "\n",
    "  # maximum stabilizer weight\n",
    "  wstab = np.max([np.sum(stab[i,:]) for i in range(m)])\n",
    "  # weight of the logical operator\n",
    "  wlog = np.count_nonzero(logicOp)\n",
    "  # how many slack variables are needed to express orthogonality constraints modulo two\n",
    "  num_anc_stab = int(np.ceil(np.log2(wstab)))\n",
    "  num_anc_logical = int(np.ceil(np.log2(wlog)))\n",
    "  # total number of variables\n",
    "  num_var = n + m*num_anc_stab + num_anc_logical\n",
    "\n",
    "  model = Model()\n",
    "  model.verbose = 0\n",
    "  x = [model.add_var(var_type=BINARY) for i in range(num_var)]\n",
    "  model.objective = minimize(xsum(x[i] for i in range(n)))\n",
    "\n",
    "  # orthogonality to rows of stab constraints\n",
    "  for row in range(m):\n",
    "    weight = [0]*num_var\n",
    "    supp = np.nonzero(stab[row,:])[0]\n",
    "    for q in supp:\n",
    "      weight[q] = 1\n",
    "    cnt = 1\n",
    "    for q in range(num_anc_stab):\n",
    "      weight[n + row*num_anc_stab +q] = -(1<<cnt)\n",
    "      cnt+=1\n",
    "    model+= xsum(weight[i] * x[i] for i in range(num_var)) == 0\n",
    "\n",
    "  # odd overlap with logicOp constraint\n",
    "  supp = np.nonzero(logicOp)[0]\n",
    "  weight = [0]*num_var\n",
    "  for q in supp:\n",
    "    weight[q] = 1\n",
    "  cnt = 1\n",
    "  for q in range(num_anc_logical):\n",
    "      weight[n + m*num_anc_stab +q] = -(1<<cnt)\n",
    "      cnt+=1\n",
    "  model+= xsum(weight[i] * x[i] for i in range(num_var)) == 1\n",
    "\n",
    "  model.optimize()\n",
    "\n",
    "  opt_val = sum([x[i].x for i in range(n)])\n",
    "\n",
    "  return int(opt_val)\n",
    "\n",
    "\n",
    "def distance_test_parallel(stab, logicOp):\n",
    "    n = stab.shape[1]  # number of qubits\n",
    "    m = stab.shape[0]  # number of stabilizers\n",
    "\n",
    "    # Parallel computation of wstab\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        wstab_list = list(executor.map(np.sum, stab))\n",
    "    wstab = np.max(wstab_list)\n",
    "\n",
    "    wlog = np.count_nonzero(logicOp)\n",
    "    num_anc_stab = int(np.ceil(np.log2(wstab)))\n",
    "    num_anc_logical = int(np.ceil(np.log2(wlog)))\n",
    "    num_var = n + m * num_anc_stab + num_anc_logical\n",
    "\n",
    "    model = Model()\n",
    "    model.verbose = 0\n",
    "    x = [model.add_var(var_type=BINARY) for i in range(num_var)]\n",
    "    model.objective = minimize(xsum(x[i] for i in range(n)))\n",
    "\n",
    "    # Function to prepare and add a constraint for a row of stab\n",
    "    def add_stab_constraint(row):\n",
    "        weight = [0] * num_var\n",
    "        supp = np.nonzero(stab[row, :])[0]\n",
    "        for q in supp:\n",
    "            weight[q] = 1\n",
    "        cnt = 1\n",
    "        for q in range(num_anc_stab):\n",
    "            weight[n + row * num_anc_stab + q] = -(1 << cnt)\n",
    "            cnt += 1\n",
    "        return xsum(weight[i] * x[i] for i in range(num_var)) == 0\n",
    "\n",
    "    # Parallel addition of orthogonality constraints\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        constraints = list(executor.map(add_stab_constraint, range(m)))\n",
    "    for constraint in constraints:\n",
    "        model += constraint\n",
    "\n",
    "    # Adding odd overlap with logicOp constraint (not parallelized)\n",
    "    supp = np.nonzero(logicOp)[0]\n",
    "    weight = [0] * num_var\n",
    "    for q in supp:\n",
    "        weight[q] = 1\n",
    "    cnt = 1\n",
    "    for q in range(num_anc_logical):\n",
    "        weight[n + m * num_anc_stab + q] = -(1 << cnt)\n",
    "        cnt += 1\n",
    "    model += xsum(weight[i] * x[i] for i in range(num_var)) == 1\n",
    "\n",
    "    model.optimize()\n",
    "    opt_val = sum(x[i].x for i in range(n))\n",
    "\n",
    "    return int(opt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "def search_codes_general(\n",
    "        l_range: range[int], \n",
    "        m_range: range[int], \n",
    "        weight_range: range[int], \n",
    "        power_range_A: range[int], \n",
    "        power_range_B: range[int], \n",
    "        encoding_rate_threshold: Optional[float],\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Searching the parameter space for good bicycle codes (BC)\n",
    "\n",
    "    args:\n",
    "        - l_range: Range of possible values for parameter l\n",
    "        - m_range: Range of possible values for parameter m\n",
    "        - weight_range: Range of code weights (= the total number of summands accumulated for both A and B)\n",
    "        - power_range_A: Range of possible values for exponents for terms in A (A is a sum over polynomials in x and y)\n",
    "        - power_range_B: Range of possible values for exponents for terms in B (B is a sum over polynomials in x and y)\n",
    "        - encoding_rate_threshold (float): the lower bound for codes to be saved for further analysis\n",
    "    \"\"\"\n",
    "    good_configs = []\n",
    "\n",
    "    try:\n",
    "\n",
    "        for l, m in product(l_range, m_range):\n",
    "            I_ell = np.identity(l, dtype=int)\n",
    "            I_m = np.identity(m, dtype=int)\n",
    "            x, y = {}, {}\n",
    "\n",
    "            # Generate base matrices x and y\n",
    "            for i in range(l):\n",
    "                x[i] = np.kron(np.roll(I_ell, i, axis=1), I_m)\n",
    "            for j in range(m):\n",
    "                y[j] = np.kron(I_ell, np.roll(I_m, j, axis=1))\n",
    "\n",
    "            # Iterate over weights and distribute them across A and B\n",
    "            for weight in weight_range:\n",
    "                for weight_A in range(1, weight):  # Ensure at least one term in A and B # TODO: Could think of also raising to the power of zero leading to identity matrix\n",
    "                    weight_B = weight - weight_A\n",
    "\n",
    "                    # Generate all combinations of summands in A and B with their respective weights\n",
    "                    summands_A = list(product(['x', 'y'], repeat=weight_A))\n",
    "                    summands_B = list(product(['x', 'y'], repeat=weight_B))\n",
    "\n",
    "                    for summand_combo_A, summand_combo_B in product(summands_A, summands_B):\n",
    "                        # Iterate over power ranges for each summand in A and B\n",
    "                        for powers_A in product(power_range_A, repeat=weight_A):\n",
    "                            for powers_B in product(power_range_B, repeat=weight_B):\n",
    "                                A, B = np.zeros((l*m, l*m), dtype=int), np.zeros((l*m, l*m), dtype=int)\n",
    "                                A_poly_sum, B_poly_sum = '', ''\n",
    "\n",
    "                                # Construct A with its summands and powers\n",
    "                                for summand, power in zip(summand_combo_A, powers_A):\n",
    "                                    matrix = x[power] if summand == 'x' else y[power]\n",
    "                                    print('A.shape:', A.shape)\n",
    "                                    print('matrix.shape:', matrix.shape)\n",
    "                                    A += matrix\n",
    "                                    A_poly_sum += f\"{summand}{power} + \"\n",
    "\n",
    "                                # Construct B with its summands and powers\n",
    "                                for summand, power in zip(summand_combo_B, powers_B):\n",
    "                                    matrix = x[power] if summand == 'x' else y[power]\n",
    "                                    print('B.shape:', B.shape)\n",
    "                                    print('matrix.shape:', matrix.shape)\n",
    "                                    B += matrix\n",
    "                                    B_poly_sum += f\"{summand}{power} + \"\n",
    "\n",
    "                                # Remove trailing ' + '\n",
    "                                A_poly_sum = A_poly_sum.rstrip(' + ')\n",
    "                                B_poly_sum = B_poly_sum.rstrip(' + ')\n",
    "\n",
    "                                # Transpose matrices A and B\n",
    "                                AT = np.transpose(A)\n",
    "                                BT = np.transpose(B)\n",
    "\n",
    "                                # Construct matrices hx and hz\n",
    "                                hx = np.hstack((A, B))\n",
    "                                hz = np.hstack((BT, AT))\n",
    "\n",
    "                                # Construct and test the CSS code\n",
    "                                qcode = css_code(hx, hz)  # Define css_code, assuming it's defined elsewhere\n",
    "                                if qcode.test():  # Define the test method for qcode\n",
    "                                    r = get_net_encoding_rate(qcode.K, qcode.N)  # Define get_net_encoding_rate\n",
    "                                    encoding_rate_threshold = 1/15 if encoding_rate_threshold is None else encoding_rate_threshold\n",
    "                                    if r > encoding_rate_threshold:  # Check your specific criteria for good configurations\n",
    "                                        code_config = {\n",
    "                                            'l': l,\n",
    "                                            'm': m,\n",
    "                                            'num_phys_qubits': qcode.N,\n",
    "                                            'num_log_qubits': qcode.K,\n",
    "                                            'lz': qcode.lz,\n",
    "                                            'lx': qcode.lx,\n",
    "                                            'k': qcode.lz.shape[0], \n",
    "                                            'encoding_rate': r,\n",
    "                                            'A_poly_sum': A_poly_sum,\n",
    "                                            'B_poly_sum': B_poly_sum\n",
    "                                        }\n",
    "                                        good_configs.append(code_config)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.logging('An error happened in the parameter space search.', e)\n",
    "        \n",
    "    return good_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific values for l, m, and weight\n",
    "l_value = range(6, 7) # only the value 6\n",
    "m_value = range(6, 7) # only the value 6\n",
    "weight_value = range(6, 7) # only the value 6\n",
    "\n",
    "# Define the power ranges for summands in A and B\n",
    "# Adjust these ranges as per the specific code you're trying to reproduce\n",
    "power_range_A = range(1, 4)  # Example range, adjust as needed\n",
    "power_range_B = range(1, 4)  # Example range, adjust as needed\n",
    "\n",
    "# Call the function with the specific values\n",
    "# good_configs = search_codes_general(\n",
    "#     l_range=[l_value], \n",
    "#     m_range=[m_value], \n",
    "#     weight_range=[weight_value], \n",
    "#     power_range_A=power_range_A, \n",
    "#     power_range_B=power_range_B\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_iterations = sum(\n",
    "    (weight - 1) * (2 ** weight) * sum(\n",
    "        (len(power_range_A) ** weight_A) * (len(power_range_B) ** (weight - weight_A))\n",
    "        for weight_A in range(1, weight)\n",
    "    )\n",
    "    for weight in weight_value\n",
    ") * len(l_value) * len(m_value)\n",
    "total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_iterations = len(l_value) * len(m_value) * len(weight_value) * ((len(weight_value) - 1) / 2) * len(power_range_A) ** (len(weight_value) - 1) * len(power_range_B) ** (len(weight_value) - 1)\n",
    "iterations_per_10_percent = total_iterations / 10\n",
    "current_progress = 0\n",
    "iteration_counter = 0\n",
    "\n",
    "logging.info(\"Starting search_codes_general. Total iterations: %d\", total_iterations)\n",
    "total_iterations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify if the code in the paper can be found/reproduced with the code search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('codes_no_distance.pickle', 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    parallel_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Code in the paper could not be found! Verify the code search function!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[39mreturn\u001b[39;00m config  \u001b[39m# Return the matching config if found\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCode in the paper could not be found! Verify the code search function!\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Return None if no match is found\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m paper_config \u001b[39m=\u001b[39m find_matching_config(parallel_data, \u001b[39m'\u001b[39;49m\u001b[39mx3 + y1 + y2\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39my3 + x1 + x2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m paper_config\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mfind_matching_config\u001b[0;34m(configs, a_poly, b_poly)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFound code in the paper!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m config  \u001b[39m# Return the matching config if found\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCode in the paper could not be found! Verify the code search function!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Code in the paper could not be found! Verify the code search function!"
     ]
    }
   ],
   "source": [
    "# Look for the first code in the paper of IBM\n",
    "criteria = {'ell': 6, 'm': 6, 'n_phys_qubits': 72, 'n_log_qubits': 12}\n",
    "\n",
    "filtered_list = [d for d in parallel_data if all(d.get(key) == value for key, value in criteria.items())]\n",
    "\n",
    "def find_matching_config(configs, a_poly, b_poly):\n",
    "    for config in configs:\n",
    "        if config.get('A_poly_sum') == a_poly and config.get('B_poly_sum') == b_poly:\n",
    "            print('Found code in the paper!')\n",
    "            return config  # Return the matching config if found\n",
    "    raise ValueError('Code in the paper could not be found! Verify the code search function!')  # Return None if no match is found\n",
    "\n",
    "paper_config = find_matching_config(parallel_data, 'x3 + y1 + y2', 'y3 + x1 + x2')\n",
    "paper_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization of code search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_code(max_ell, max_m, num_summands_a, num_summands_b):\n",
    "    all_configs = []\n",
    "    args_list = []\n",
    "\n",
    "    for ell in range(6, max_ell + 1):\n",
    "        for m in range(6, max_m + 1):\n",
    "            for fixed_x_exponent_a in range(1, 4):\n",
    "                for fixed_y_exponent_b in range(1, 4):\n",
    "                    args_list.append((ell, m, fixed_x_exponent_a, fixed_y_exponent_b, num_summands_a, num_summands_b))\n",
    "\n",
    "    # Determine the number of processes to use\n",
    "    num_processes = min(multiprocessing.cpu_count(), len(args_list))\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(process_combination, args_list)\n",
    "\n",
    "    # Flatten the list of lists\n",
    "    for result in results:\n",
    "        all_configs.extend(result)\n",
    "\n",
    "    return all_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Surpress the print statements of the qcode.test() function\n",
    "# Save the current stdout so we can restore it later\n",
    "original_stdout = sys.stdout\n",
    "# Redirect stdout to a dummy StringIO object\n",
    "sys.stdout = io.StringIO()\n",
    "\n",
    "good_configs_parallel = build_code(\n",
    "    max_ell=6, \n",
    "    max_m=6, \n",
    "    num_summands_a=3, \n",
    "    num_summands_b=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ell': 6,\n",
       " 'm': 6,\n",
       " 'n_phys_qubits': 72,\n",
       " 'n_log_qubits': 12,\n",
       " 'encoding_rate': 0.08333333333333333,\n",
       " 'A_poly_sum': 'x3 + y1 + y2',\n",
       " 'B_poly_sum': 'y3 + x1 + x2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list = [d for d in good_configs_parallel if all(d.get(key) == value for key, value in criteria.items())]\n",
    "\n",
    "def find_matching_config(configs, a_poly, b_poly):\n",
    "    for config in configs:\n",
    "        if config.get('A_poly_sum') == a_poly and config.get('B_poly_sum') == b_poly:\n",
    "            print('Found code in the paper!')\n",
    "            return config  # Return the matching config if found\n",
    "    raise ValueError('Code in the paper could not be found! Verify the code search function!')  # Return None if no match is found\n",
    "\n",
    "paper_config = find_matching_config(good_configs_parallel, 'x3 + y1 + y2', 'y3 + x1 + x2')\n",
    "paper_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild a code from a configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re  # For parsing the polynomial strings\n",
    "\n",
    "def rebuild_code(config):\n",
    "    # Extract configuration details\n",
    "    ell = config['ell']\n",
    "    m = config['m']\n",
    "    A_poly_sum = config['A_poly_sum']\n",
    "    B_poly_sum = config['B_poly_sum']\n",
    "\n",
    "    # Define cyclic shift matrices\n",
    "    I_ell = np.identity(ell, dtype=int)\n",
    "    I_m = np.identity(m, dtype=int)\n",
    "    x, y = {}, {}\n",
    "    for i in range(ell):\n",
    "        x[i] = np.kron(np.roll(I_ell, i, axis=1), I_m)\n",
    "    for i in range(m):\n",
    "        y[i] = np.kron(I_ell, np.roll(I_m, i, axis=1))\n",
    "\n",
    "    # Initialize A and B matrices\n",
    "    A = np.zeros((ell*m, ell*m), dtype=int)\n",
    "    B = np.zeros((ell*m, ell*m), dtype=int)\n",
    "\n",
    "    # Parse A_poly_sum and B_poly_sum to construct A and B\n",
    "    for term in re.findall(r'([xy]\\d+)', A_poly_sum):\n",
    "        idx = int(term[1:]) - 1  # Convert term to 0-based index\n",
    "        if term.startswith('x') and idx < ell:\n",
    "            A += x[idx]\n",
    "        elif term.startswith('y') and (idx < m):\n",
    "            A += y[idx]\n",
    "\n",
    "    for term in re.findall(r'([xy]\\d+)', B_poly_sum):\n",
    "        idx = int(term[1:]) - 1  # Convert term to 0-based index\n",
    "        if term.startswith('x') and idx < ell:\n",
    "            B += x[idx]\n",
    "        elif term.startswith('y') and (idx < m):\n",
    "            B += y[idx]\n",
    "\n",
    "    # Ensure matrices are binary\n",
    "    A %= 2\n",
    "    B %= 2\n",
    "\n",
    "    # Transpose matrices A and B\n",
    "    AT = np.transpose(A)\n",
    "    BT = np.transpose(B)\n",
    "\n",
    "    # Construct matrices hx and hz\n",
    "    hx = np.hstack((A, B))\n",
    "    hz = np.hstack((BT, AT))\n",
    "\n",
    "    qcode = css_code(hx, hz)\n",
    "\n",
    "    # Construct and return the CSS code using hx and hz\n",
    "    return {\n",
    "        'qcode': qcode,\n",
    "        'hx': hx,\n",
    "        'hz': hz,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_info = rebuild_code(paper_config)\n",
    "print('CSS code rebuilt based on the configuration.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
